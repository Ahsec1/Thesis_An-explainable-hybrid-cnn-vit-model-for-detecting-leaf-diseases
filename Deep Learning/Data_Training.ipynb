{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03987a07-2376-4dea-ad65-ef1b51c3be7b",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce3f185-ec4b-480d-91a1-1da45c548e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Creating normalized datasets...\n",
      "Dataset loaded: 66156 images, 18 classes\n",
      "Classes: ['Banana_Leaf_Disease_Dataset_Bangladesh_Healthy', 'Banana_Leaf_Disease_Dataset_Bangladesh_Panama Disease', 'Banana_Leaf_Disease_Dataset_Bangladesh_Yellow and Black Sigatoka', 'Banana_Leaf_Disease_Dataset_Bangladesh_cordana', 'Banana_Leaf_Disease_Dataset_Bangladesh_pestalotiopsis', 'Coconut Tree Disease Dataset_Bud Root Dropping', 'Coconut Tree Disease Dataset_Bud Rot', 'Coconut Tree Disease Dataset_Gray Leaf Spot', 'Coconut Tree Disease Dataset_Healthy_Leaves', 'Coconut Tree Disease Dataset_Leaf Rot', 'Coconut Tree Disease Dataset_WCLWD_DryingofLeaflets', 'Coconut Tree Disease Dataset_WCLWD_Flaccidity', 'Coconut Tree Disease Dataset_WCLWD_Yellowing', 'Sugarcane Leaf Disease Dataset_Healthy', 'Sugarcane Leaf Disease Dataset_Mosaic', 'Sugarcane Leaf Disease Dataset_RedRot', 'Sugarcane Leaf Disease Dataset_Rust', 'Sugarcane Leaf Disease Dataset_Yellow']\n",
      "Dataset loaded: 2365 images, 18 classes\n",
      "Classes: ['Banana_Leaf_Disease_Dataset_Bangladesh_Healthy', 'Banana_Leaf_Disease_Dataset_Bangladesh_Panama Disease', 'Banana_Leaf_Disease_Dataset_Bangladesh_Yellow and Black Sigatoka', 'Banana_Leaf_Disease_Dataset_Bangladesh_cordana', 'Banana_Leaf_Disease_Dataset_Bangladesh_pestalotiopsis', 'Coconut Tree Disease Dataset_Bud Root Dropping', 'Coconut Tree Disease Dataset_Bud Rot', 'Coconut Tree Disease Dataset_Gray Leaf Spot', 'Coconut Tree Disease Dataset_Healthy_Leaves', 'Coconut Tree Disease Dataset_Leaf Rot', 'Coconut Tree Disease Dataset_WCLWD_DryingofLeaflets', 'Coconut Tree Disease Dataset_WCLWD_Flaccidity', 'Coconut Tree Disease Dataset_WCLWD_Yellowing', 'Sugarcane Leaf Disease Dataset_Healthy', 'Sugarcane Leaf Disease Dataset_Mosaic', 'Sugarcane Leaf Disease Dataset_RedRot', 'Sugarcane Leaf Disease Dataset_Rust', 'Sugarcane Leaf Disease Dataset_Yellow']\n",
      "Dataset loaded: 2375 images, 18 classes\n",
      "Classes: ['Banana_Leaf_Disease_Dataset_Bangladesh_Healthy', 'Banana_Leaf_Disease_Dataset_Bangladesh_Panama Disease', 'Banana_Leaf_Disease_Dataset_Bangladesh_Yellow and Black Sigatoka', 'Banana_Leaf_Disease_Dataset_Bangladesh_cordana', 'Banana_Leaf_Disease_Dataset_Bangladesh_pestalotiopsis', 'Coconut Tree Disease Dataset_Bud Root Dropping', 'Coconut Tree Disease Dataset_Bud Rot', 'Coconut Tree Disease Dataset_Gray Leaf Spot', 'Coconut Tree Disease Dataset_Healthy_Leaves', 'Coconut Tree Disease Dataset_Leaf Rot', 'Coconut Tree Disease Dataset_WCLWD_DryingofLeaflets', 'Coconut Tree Disease Dataset_WCLWD_Flaccidity', 'Coconut Tree Disease Dataset_WCLWD_Yellowing', 'Sugarcane Leaf Disease Dataset_Healthy', 'Sugarcane Leaf Disease Dataset_Mosaic', 'Sugarcane Leaf Disease Dataset_RedRot', 'Sugarcane Leaf Disease Dataset_Rust', 'Sugarcane Leaf Disease Dataset_Yellow']\n",
      "âœ… Normalization setup complete!\n",
      "Training samples: 66156\n",
      "Validation samples: 2365\n",
      "Test samples: 2375\n",
      "Number of classes: 18\n",
      "Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "# Directory Paths\n",
    "AUGMENT_DIR = r\"C:\\Users\\USER\\Documents\\Thesis Dataset\\Processed Dataset\\train_augmented\"\n",
    "VAL_DIR     = r\"C:\\Users\\USER\\Documents\\Thesis Dataset\\Processed Dataset\\val\"\n",
    "TEST_DIR    = r\"C:\\Users\\USER\\Documents\\Thesis Dataset\\Processed Dataset\\test\"\n",
    "IMG_EXTENSIONS = (\".jpg\", \".jpeg\", \".png\")\n",
    "\n",
    "# Parameters for Normalization\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Data Transfroms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "# Printing the Datasets and its classes\n",
    "class PlantDiseaseDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.class_to_idx = {}\n",
    "        \n",
    "        class_idx = 0\n",
    "        for crop_type in sorted(os.listdir(data_dir)):\n",
    "            crop_path = os.path.join(data_dir, crop_type)\n",
    "            if not os.path.isdir(crop_path):\n",
    "                continue\n",
    "                \n",
    "            for disease_class in sorted(os.listdir(crop_path)):\n",
    "                class_path = os.path.join(crop_path, disease_class)\n",
    "                if not os.path.isdir(class_path):\n",
    "                    continue\n",
    "                \n",
    "                full_class_name = f\"{crop_type}_{disease_class}\"\n",
    "                if full_class_name not in self.class_to_idx:\n",
    "                    self.class_to_idx[full_class_name] = class_idx\n",
    "                    class_idx += 1\n",
    "                \n",
    "                for img_file in os.listdir(class_path):\n",
    "                    if img_file.lower().endswith(IMG_EXTENSIONS):\n",
    "                        img_path = os.path.join(class_path, img_file)\n",
    "                        self.images.append(img_path)\n",
    "                        self.labels.append(self.class_to_idx[full_class_name])\n",
    "        \n",
    "        print(f\"Dataset loaded: {len(self.images)} images, {len(self.class_to_idx)} classes\")\n",
    "        print(f\"Classes: {list(self.class_to_idx.keys())}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Normalization Phase\n",
    "print(\"ðŸ”„ Creating normalized datasets...\")\n",
    "\n",
    "train_dataset = PlantDiseaseDataset(AUGMENT_DIR, transform=train_transforms)\n",
    "val_dataset = PlantDiseaseDataset(VAL_DIR, transform=val_test_transforms)\n",
    "test_dataset = PlantDiseaseDataset(TEST_DIR, transform=val_test_transforms)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=4,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=4,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=4,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print(\"âœ… Normalization setup complete!\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Number of classes: {len(train_dataset.class_to_idx)}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "# Verify whether the normalization works\n",
    "def verify_normalization():\n",
    "    \"\"\"Verify that normalization is applied correctly\"\"\"\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    images, labels = sample_batch\n",
    "    \n",
    "    print(\"\\nðŸ“Š Normalization Verification:\")\n",
    "    print(f\"Image tensor shape: {images.shape}\")\n",
    "    print(f\"Image tensor range: [{images.min():.3f}, {images.max():.3f}]\")\n",
    "    print(f\"Mean per channel: {images.mean(dim=[0,2,3])}\")\n",
    "    print(f\"Std per channel: {images.std(dim=[0,2,3])}\")\n",
    "    print(\"âœ… If values are close to meanâ‰ˆ[0,0,0] and stdâ‰ˆ[1,1,1], normalization is working!\")\n",
    "\n",
    "verify_normalization()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a5ef23-8705-4297-9043-f27b448fd5bb",
   "metadata": {},
   "source": [
    "### Train CNN-ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4333d767-7e3a-4c12-849a-60a47af601cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from timm import create_model\n",
    "\n",
    "# ---- CONFIG ----\n",
    "AUGMENT_DIR = r\"C:\\Users\\USER\\Documents\\Thesis Dataset\\Processed Dataset\\train_augmented\"\n",
    "VAL_DIR     = r\"C:\\Users\\USER\\Documents\\Thesis Dataset\\Processed Dataset\\val\"\n",
    "TEST_DIR    = r\"C:\\Users\\USER\\Documents\\Thesis Dataset\\Processed Dataset\\test\"\n",
    "IMG_EXTENSIONS = (\".jpg\", \".jpeg\", \".png\")\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 18\n",
    "\n",
    "# ---- DATA LOADING ----\n",
    "data_transforms = {  \n",
    "    'train': transforms.Compose([transforms.ToTensor()]),\n",
    "    'val': transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "\n",
    "train_dataset = datasets.ImageFolder(AUGMENT_DIR, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(VAL_DIR, transform=data_transforms['val'])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# ---- MODEL LOADING ----\n",
    "def get_resnet50(num_classes):\n",
    "    model = models.resnet50(weights='IMAGENET1K_V2')\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def get_efficientnet_b0(num_classes):\n",
    "    model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
    "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def get_vit_small(num_classes):\n",
    "    model = create_model(\"vit_small_patch16_224\", pretrained=True, num_classes=num_classes)\n",
    "    return model\n",
    "\n",
    "models_dict = {\n",
    "    'resnet50': get_resnet50(NUM_CLASSES),\n",
    "    'efficientnet_b0': get_efficientnet_b0(NUM_CLASSES),\n",
    "    'vit_small': get_vit_small(NUM_CLASSES)\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "for name in models_dict:\n",
    "    models_dict[name] = models_dict[name].to(device)\n",
    "\n",
    "# ---- TRAINING ----\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, targets in dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "def validate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "NUM_EPOCHS = 25\n",
    "for model_name, model in models_dict.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS} - Train Acc: {train_acc:.4f} - Val Acc: {val_acc:.4f}\")\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), f\"{model_name}_best.pth\")\n",
    "    print(f\"Finished training {model_name} with best val acc: {best_val_acc:.4f}\")\n",
    "\n",
    "# ---- ENSEMBLE PREDICTION EXAMPLE ----\n",
    "def ensemble_predict(models_dict, inputs, weights=None):\n",
    "    models = [model.eval() for model in models_dict.values()]\n",
    "    if weights is None:\n",
    "        weights = [1/len(models)] * len(models)\n",
    "    logits = [model(inputs.to(device)) * w for model, w in zip(models, weights)]\n",
    "    return torch.sum(torch.stack(logits), dim=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
